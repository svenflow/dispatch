#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.11"
# dependencies = ["requests", "rich"]
# ///
"""
LakeHomes.com CLI - Search Vermont lake properties

Uses LakeHomes API with session-based auth (cookies from Chrome).

Usage:
    lakehomes lakes                   # List all Vermont lakes with listings
    lakehomes search <lake_id>        # Get listings for a specific lake
    lakehomes details <listing_url>   # Get details for a specific listing
"""

import argparse
import base64
import json
import subprocess
import sys
from pathlib import Path

import requests
from rich.console import Console
from rich.table import Table

console = Console()

# Chrome control CLI path
CHROME_CLI = Path.home() / ".claude/skills/chrome-control/scripts/chrome"


def get_session_from_chrome() -> str | None:
    """Extract sessionId cookie from Chrome tab on lakehomes.com"""
    try:
        # First check if there's a lakehomes tab open
        result = subprocess.run(
            [str(CHROME_CLI), "tabs"],
            capture_output=True,
            text=True,
        )

        tab_id = None
        lines = result.stdout.strip().split('\n')
        for i, line in enumerate(lines):
            if 'lakehomes.com' in line.lower():
                # URL is on this line, tab ID is on previous line
                if i > 0:
                    prev_line = lines[i - 1].strip()
                    parts = prev_line.split()
                    if parts and parts[0].isdigit():
                        tab_id = parts[0]
                        break
                # Or it might be on same line
                parts = line.strip().split()
                if parts and parts[0].isdigit():
                    tab_id = parts[0]
                    break

        if not tab_id:
            # Open lakehomes.com to get a session
            result = subprocess.run(
                [str(CHROME_CLI), "open", "https://www.lakehomes.com/vermont"],
                capture_output=True,
                text=True,
            )
            # Parse tab ID from output
            for line in result.stdout.strip().split('\n'):
                if 'Opened tab' in line:
                    parts = line.split()
                    for i, p in enumerate(parts):
                        if p == 'tab':
                            tab_id = parts[i + 1].rstrip(':')
                            break

            if tab_id:
                import time
                time.sleep(2)  # Wait for page to load

        if tab_id:
            # Get sessionId cookie
            result = subprocess.run(
                [str(CHROME_CLI), "js", tab_id,
                 "document.cookie.match(/sessionId=([^;]+)/)?.[1] || ''"],
                capture_output=True,
                text=True,
            )
            session_id = result.stdout.strip()
            if session_id:
                return session_id

    except Exception as e:
        console.print(f"[yellow]Warning: Could not get session from Chrome: {e}[/yellow]")

    return None


def make_request(endpoint: str, session_id: str) -> dict | None:
    """Make authenticated request to LakeHomes API"""
    auth_string = base64.b64encode(f'{session_id}:'.encode()).decode()

    headers = {
        'Authorization': f'Basic {auth_string}',
        'User-Agent': 'Mozilla/5.0',
        'Accept': 'application/json'
    }

    cookies = {'sessionId': session_id}

    url = f"https://www.lakehomes.com/api{endpoint}"

    try:
        resp = requests.get(url, headers=headers, cookies=cookies, timeout=30)
        resp.raise_for_status()
        return resp.json()
    except requests.RequestException as e:
        console.print(f"[red]API error: {e}[/red]")
        return None


def cmd_lakes(args, session_id: str):
    """List all Vermont lakes with listings"""
    data = make_request("/states/VT", session_id)
    if not data:
        return 1

    state = data.get('state', {})
    lakes = state.get('nicheItemsPreviewInfo', [])

    # Filter to lakes with listings
    lakes_with_listings = [
        l for l in lakes
        if l.get('more', {}).get('listings', 0) > 0
    ]

    # Sort by listing count
    lakes_with_listings.sort(key=lambda x: x.get('more', {}).get('listings', 0), reverse=True)

    table = Table(title=f"Vermont Lakes with Listings ({len(lakes_with_listings)} lakes)")
    table.add_column("Lake ID", style="cyan")
    table.add_column("Lake Name", style="green")
    table.add_column("Listings", justify="right", style="yellow")
    table.add_column("URL Path", style="dim")

    for lake in lakes_with_listings:
        more = lake.get('more', {})
        table.add_row(
            str(more.get('id', 'N/A')),
            lake.get('value', 'Unknown'),
            str(more.get('listings', 0)),
            lake.get('valueLink', '')
        )

    console.print(table)
    return 0


def cmd_search(args, session_id: str):
    """Search listings for a specific lake"""
    lake_id = args.lake_id

    data = make_request(f"/states/VT/niches/{lake_id}", session_id)
    if not data:
        return 1

    niche = data.get('nicheItem', {})
    lake_name = niche.get('displayName', 'Unknown Lake')

    listings_data = data.get('listingsPreview', {})
    if isinstance(listings_data, dict):
        total = listings_data.get('total_count', 0)
        results = listings_data.get('results', [])
    else:
        results = []
        total = 0

    console.print(f"\n[bold]{lake_name}[/bold] - {total} listings\n")

    if not results:
        console.print("[yellow]No listings found[/yellow]")
        return 0

    table = Table()
    table.add_column("Price", style="green", justify="right")
    table.add_column("Beds", justify="center")
    table.add_column("Baths", justify="center")
    table.add_column("SqFt", justify="right")
    table.add_column("Acres", justify="right")
    table.add_column("URL", style="dim")

    for listing in results:
        price = listing.get('price')
        price_str = f"${price:,}" if price else "N/A"

        beds = listing.get('bedrooms')
        beds_str = str(beds) if beds else "-"

        baths = listing.get('bathrooms')
        baths_str = str(baths) if baths else "-"

        sqft = listing.get('sqft', {})
        if isinstance(sqft, dict):
            sqft_str = sqft.get('readable', '-')
        else:
            sqft_str = str(sqft) if sqft else "-"

        acres = listing.get('acres')
        acres_str = f"{acres:.2f}" if acres else "-"

        url = listing.get('urlPath', '')

        table.add_row(price_str, beds_str, baths_str, sqft_str, acres_str, url)

    console.print(table)
    return 0


def cmd_details(args, session_id: str):
    """Get details for a specific listing (by URL path)"""
    # Parse URL to get the listing info
    url_path = args.listing_url

    if url_path.startswith('http'):
        # Extract path from full URL
        from urllib.parse import urlparse
        parsed = urlparse(url_path)
        url_path = parsed.path

    # The URL contains the MLS ID at the end like lhrmls-03078326
    if 'lhrmls-' not in url_path:
        console.print("[red]Invalid listing URL - must contain lhrmls ID[/red]")
        return 1

    # Extract components from URL like /vermont/lake-seymour/3604-vt-route-111-morgan-vt-05853-lhrmls-03078326
    parts = url_path.strip('/').split('/')
    if len(parts) < 3:
        console.print("[red]Invalid URL format[/red]")
        return 1

    state = parts[0]
    lake = parts[1]
    listing = parts[2]

    # Try to get listing details
    data = make_request(f"/{state}/{lake}/{listing}", session_id)
    if not data:
        console.print(f"[yellow]Could not fetch details. Opening in browser...[/yellow]")
        full_url = f"https://www.lakehomes.com{url_path}"
        subprocess.run([str(CHROME_CLI), "open", full_url])
        return 0

    console.print(json.dumps(data, indent=2))
    return 0


def main():
    parser = argparse.ArgumentParser(description="LakeHomes.com Vermont Property Search")
    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # lakes command
    lakes_parser = subparsers.add_parser("lakes", help="List all Vermont lakes with listings")

    # search command
    search_parser = subparsers.add_parser("search", help="Search listings for a specific lake")
    search_parser.add_argument("lake_id", type=int, help="Lake ID from 'lakes' command")

    # details command
    details_parser = subparsers.add_parser("details", help="Get listing details")
    details_parser.add_argument("listing_url", help="Listing URL path or full URL")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    # Get session from Chrome
    console.print("[dim]Getting session from Chrome...[/dim]")
    session_id = get_session_from_chrome()

    if not session_id:
        console.print("[red]Could not get session. Make sure Chrome is open with lakehomes.com[/red]")
        return 1

    console.print(f"[dim]Session: {session_id[:8]}...[/dim]\n")

    if args.command == "lakes":
        return cmd_lakes(args, session_id)
    elif args.command == "search":
        return cmd_search(args, session_id)
    elif args.command == "details":
        return cmd_details(args, session_id)

    return 0


if __name__ == "__main__":
    sys.exit(main())
