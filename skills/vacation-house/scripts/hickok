#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.11"
# dependencies = ["requests", "rich", "beautifulsoup4"]
# ///
"""
Hickok & Boardman Real Estate CLI - Vermont ski properties

Scrapes listings from hickokandboardman.com with Chrome cookies.

Usage:
    hickok search                 # List all VT ski area homes (no condos)
    hickok search --town Stowe    # Filter by town
    hickok search --min-beds 3    # Filter by min bedrooms
"""

import argparse
import re
import subprocess
import sys
from pathlib import Path

import requests
from bs4 import BeautifulSoup
from rich.console import Console
from rich.table import Table

console = Console()

CHROME_CLI = Path.home() / ".claude/skills/chrome-control/scripts/chrome"

SKI_RESORTS_URL = "https://www.hickokandboardman.com/vermont/special-markets/homes-sale-near-vermont-ski-resorts.html"


def get_cookies_from_chrome() -> dict:
    """Get cookies from Chrome tab on hickokandboardman.com"""
    try:
        result = subprocess.run(
            [str(CHROME_CLI), "tabs"],
            capture_output=True,
            text=True,
        )

        tab_id = None
        lines = result.stdout.strip().split('\n')
        for i, line in enumerate(lines):
            if 'hickokandboardman.com' in line.lower():
                if i > 0:
                    prev_line = lines[i - 1].strip()
                    parts = prev_line.split()
                    if parts and parts[0].isdigit():
                        tab_id = parts[0]
                        break

        if not tab_id:
            # Open the site
            result = subprocess.run(
                [str(CHROME_CLI), "open", SKI_RESORTS_URL],
                capture_output=True,
                text=True,
            )
            for line in result.stdout.strip().split('\n'):
                if 'Opened tab' in line:
                    parts = line.split()
                    for j, p in enumerate(parts):
                        if p == 'tab':
                            tab_id = parts[j + 1].rstrip(':')
                            break
            if tab_id:
                import time
                time.sleep(3)

        if tab_id:
            result = subprocess.run(
                [str(CHROME_CLI), "js", tab_id, "document.cookie"],
                capture_output=True,
                text=True,
            )
            cookie_str = result.stdout.strip()
            cookies = {}
            for part in cookie_str.split(';'):
                if '=' in part:
                    key, val = part.strip().split('=', 1)
                    cookies[key] = val
            return cookies

    except Exception as e:
        console.print(f"[yellow]Warning: {e}[/yellow]")

    return {}


def fetch_listings(cookies: dict) -> list[dict]:
    """Fetch and parse listings from the ski resorts page"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36'
    }

    resp = requests.get(SKI_RESORTS_URL, headers=headers, cookies=cookies, timeout=30)
    resp.raise_for_status()

    soup = BeautifulSoup(resp.text, 'html.parser')
    listings = []

    for item in soup.select('.listing'):
        try:
            # Get the link
            link = item.select_one('a[href*="/real-estate/"]')
            url = link['href'] if link else None

            # Parse text content
            text = item.get_text('\n', strip=True)

            # Extract MLS#
            mls_match = re.search(r'MLS#\s*(\d+)', text)
            mls = mls_match.group(1) if mls_match else None

            # Extract price
            price_match = re.search(r'Price:\s*\$?([\d,]+)', text)
            price = int(price_match.group(1).replace(',', '')) if price_match else None

            # Extract type
            type_match = re.search(r'(House|Condo|Townhouse|Land|Mobile Home|Multi-Family)\s*Type', text)
            prop_type = type_match.group(1) if type_match else 'Unknown'

            # Extract beds/baths
            beds_match = re.search(r'(\d+)\s*Beds', text)
            beds = int(beds_match.group(1)) if beds_match else None

            baths_match = re.search(r'(\d+)\s*Baths', text)
            baths = int(baths_match.group(1)) if baths_match else None

            # Extract sqft and acres
            sqft_match = re.search(r'([\d,]+)\s*Sqft', text)
            sqft = int(sqft_match.group(1).replace(',', '')) if sqft_match else None

            acres_match = re.search(r'([\d.]+)\s*Acres', text)
            acres = float(acres_match.group(1)) if acres_match else None

            # Extract address and town from text
            lines = text.split('\n')
            address = lines[0] if lines else ''
            town = lines[1] if len(lines) > 1 else ''

            listings.append({
                'mls': mls,
                'price': price,
                'type': prop_type,
                'beds': beds,
                'baths': baths,
                'sqft': sqft,
                'acres': acres,
                'address': address,
                'town': town,
                'url': url
            })

        except Exception as e:
            continue

    return listings


def cmd_search(args, cookies: dict):
    """Search ski area listings"""
    console.print("[dim]Fetching listings...[/dim]")
    listings = fetch_listings(cookies)

    # Filter out condos (user requested no condos)
    listings = [l for l in listings if l['type'] not in ('Condo', 'Townhouse')]

    # Apply filters
    if args.town:
        listings = [l for l in listings if args.town.lower() in l['town'].lower()]

    if args.min_beds:
        listings = [l for l in listings if l['beds'] and l['beds'] >= args.min_beds]

    if args.min_baths:
        listings = [l for l in listings if l['baths'] and l['baths'] >= args.min_baths]

    if args.min_price:
        listings = [l for l in listings if l['price'] and l['price'] >= args.min_price]

    if args.max_price:
        listings = [l for l in listings if l['price'] and l['price'] <= args.max_price]

    if args.min_acres:
        listings = [l for l in listings if l['acres'] and l['acres'] >= args.min_acres]

    # JSON output mode
    if args.json:
        import json
        output = []
        for l in listings:
            output.append({
                'price': l['price'],
                'beds': l['beds'],
                'baths': l['baths'],
                'sqft': l['sqft'],
                'acres': l['acres'],
                'address': l['address'],
                'city': l['town'],
                'state': 'VT',
                'url': l['url'],
                'image_url': '',  # Hickok doesn't expose images in list view
                'source': 'hickok',
            })
        print(json.dumps(output))
        return 0

    console.print(f"\n[bold]Vermont Ski Area Homes[/bold] - {len(listings)} listings (no condos)\n")

    if not listings:
        console.print("[yellow]No listings match your criteria[/yellow]")
        return 0

    table = Table()
    table.add_column("Price", style="green", justify="right")
    table.add_column("Beds", justify="center")
    table.add_column("Baths", justify="center")
    table.add_column("SqFt", justify="right")
    table.add_column("Acres", justify="right")
    table.add_column("Town", style="cyan")
    table.add_column("Address", style="dim")

    for l in listings[:30]:  # Limit to 30 for readability
        price_str = f"${l['price']:,}" if l['price'] else "-"
        beds_str = str(l['beds']) if l['beds'] else "-"
        baths_str = str(l['baths']) if l['baths'] else "-"
        sqft_str = f"{l['sqft']:,}" if l['sqft'] else "-"
        acres_str = f"{l['acres']:.2f}" if l['acres'] else "-"

        table.add_row(
            price_str, beds_str, baths_str, sqft_str, acres_str,
            l['town'], l['address'][:30]
        )

    console.print(table)

    if len(listings) > 30:
        console.print(f"\n[dim]Showing 30 of {len(listings)} results. Use filters to narrow down.[/dim]")

    return 0


def main():
    parser = argparse.ArgumentParser(description="Hickok & Boardman VT Ski Properties")
    subparsers = parser.add_subparsers(dest="command", help="Commands")

    search_parser = subparsers.add_parser("search", help="Search ski area listings")
    search_parser.add_argument("--town", help="Filter by town name")
    search_parser.add_argument("--min-beds", type=int, help="Minimum bedrooms")
    search_parser.add_argument("--min-baths", type=int, help="Minimum bathrooms")
    search_parser.add_argument("--min-price", type=int, help="Minimum price")
    search_parser.add_argument("--max-price", type=int, help="Maximum price")
    search_parser.add_argument("--min-acres", type=float, help="Minimum acreage")
    search_parser.add_argument("--json", action="store_true", help="Output JSON")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    console.print("[dim]Getting cookies from Chrome...[/dim]")
    cookies = get_cookies_from_chrome()

    if not cookies:
        console.print("[red]Could not get cookies. Make sure Chrome is open.[/red]")
        return 1

    if args.command == "search":
        return cmd_search(args, cookies)

    return 0


if __name__ == "__main__":
    sys.exit(main())
